---
  title: "Methods and Results"
  author: 
  date: "`r Sys.Date()`"
  bibliography: refs.bib
  csl: pnas.csl
  output: 
    bookdown::word_document2:
      toc: no
      toc_depth: 6
      number_sections: false
      reference_docx: template.docx
    bookdown::html_document2:
      code_folding: hide
      number_sections: no
      toc: yes
      toc_depth: 6
      toc_float: yes
  editor_options: 
    chunk_output_type: console
---
```{r setup, include=FALSE}
  knitr::opts_chunk$set(echo = FALSE, cache = TRUE, message = FALSE, warning = FALSE, tidy = TRUE, fig.width = 10)
  ## numbers >= 10^5 will be denoted in scientific notation,      ## numbers >= 10^5 will be denoted in scientific notation,
    ## and rounded to 2 digits      ## and rounded to 2 digits
    options(digits = 2)
```

```{r loadpackages, echo = FALSE, results = "hide"}
  pacman::p_load(tidyverse, metafor, brms, metaAidR, ape, phytools, metaAidR, orchaRd, gt, kableExtra, flextable, patchwork, latex2exp, MuMIn, equatiomatic, magrittr, data.table)
eval(metafor:::.MuMIn)
source("./R/func.R")  
  
```
```{r loaddata, echo = FALSE, results = "hide"}
################
# Tree
################
      data <- read.csv("./data/meta_data.csv")
      data <- data %>% 
              mutate(species2 = species)
  
  # Bring in and prune tree
       tree <- read.tree("./phylogeny/tree")
       tree$tip.label <- gsub("_", " ", tree$tip.label)
  phylogeny <- vcv(tree, corr=TRUE)

  # Summary statistics for the results
  inverts <- data %>% 
             mutate(insect = ifelse(class %in% c("Insecta", "Gastropoda", "Malacostraca", "Arachnida", "Clitellata (Phylum Annelida)",  "Secernentea (Phylum Nematoda)"), 1,0))

  parity <- data %>% group_by(species) %>% summarise(parity = unique(Gestation)) %>% group_by(parity) %>% summarise(n=n())
  
  # Number of effects per study
  n_eff_study <- data %>%
                  group_by(study) %>%
                  summarise(n = n())
  n_eff_study <- range(n_eff_study$n)

###################
# Multilevel Meta-analytic Models (intercept only), plus robust variace estimation test.
###################
  
  model1.1 <- rma.mv(SMDH ~ 1, V = data$v_SMDH, 
                     random = list(~1|study, ~1|variable, ~1|species, ~1|obs), test = "t", data = data)
    robust <- robust(model1.1, cluster = data$study, vcov = "CR2")
  
  model1.2 <- rma.mv(SMDH ~ 1, V = data$v_SMDH, 
                     random = list(~1|study, ~1|variable, ~1|species, ~1|species2, ~1|obs), R = list(species2 = phylogeny), test = "t", data = data)
  
   aics <- AICc(model1.2, model1.1) # Phylogeny explains very little variation; model without phylogeny better supported, even if slightly. Just keep species in model
  dAICc <- max(aics$AICc) - min(aics$AICc)

# Table 1: Effect, confidemce intervals, prediction intervals, heterogenity
   hetero_table <- metaAidR::I2(model1.1, v = data$v_SMDH, obs = "obs") # Same as orchaRd::i2_ml(model1.1)    
   hetero_table_phylo <- metaAidR::I2(model1.2, v = data$v_SMDH, phylo = "species2", obs = "obs") # Same as orchaRd::i2_ml(model1.1)    
         table1 <- make_table(robust, heteroTable = hetero_table)

###################
# Publication bias. Based on funnel plot, it looks like pub bias. Correct effect as a sensitivity analysis
###################
  
     data$inv_n_eff <- with(data, (N_C + N_T) / (N_C * N_T))
  
       model1.1_pub <- rma.mv(SMDH ~ sqrt(inv_n_eff), V = data$v_SMDH, 
                              random = list(~1|study, ~1|variable, ~1|species, ~1|obs), test = "t", data = data)
  
  model1.1_pub_full <- rma.mv(SMDH ~ sqrt(inv_n_eff) + SSD_lnRR + Harm_type, V = data$v_SMDH, 
                              random = list(~1|study, ~1|variable, ~1|species, ~1|obs), test = "t", data = data)

###################
# Meta-regressions
###################
  
  model1.3 <- rma.mv(SMDH ~ scale(SSD_lnRR), V = data$v_SMDH, 
                     random = list(~1|study, ~1|variable, ~1|species, ~1|obs), test = "t", data = data)
  robust(model1.3, cluster = data$study)
  
  r2_SSD=r2_ml(model1.3)

  model1.4 <- rma.mv(SMDH ~ Harm_type-1, V = data$v_SMDH, 
                     random = list(~1|study, ~1|species, ~1|obs), test = "t", data = data)
  robust(model1.4, cluster = data$study)

  r2_ml(model1.4)
  
  # Model that contains harm type and SSD. Harmtype appears to have different variances, so I'll check whether it is safe to assume homogeneity of variance across groups
  model1.5 <- rma.mv(SMDH ~  Harm_type + scale(SSD_lnRR), V = data$v_SMDH, 
                     random = list(~1|study, ~1|obs, ~1|species), test = "t", data = data)
  
  model1.6 <- rma.mv(SMDH ~ Harm_type + scale(SSD_lnRR), V = data$v_SMDH, 
                     random = list(~1|study, ~(1 + Harm_type)|obs, ~1|species), 
                     rho = 0, struc = "HCS", test = "t", data = data)
  
  # Compare AICc for each model
    aicc_het <- AICc(model1.5, model1.6)
  d_aicc_het <- max(aicc_het$AICc) - min(aicc_het$AICc) # Delta suggests homogeneity model better
  
  # Check robustness of results using sandwich estimator
  robust_model1.5 <- robust(model1.5, cluster = data$study, vcov = "CR2")
  predict(robust_model1.5)
  
  # Now reparameterize model
  model1.5_2 <- rma.mv(SMDH ~ 0 + Harm_type + scale(SSD_lnRR), V = data$v_SMDH, 
                     random = list(~1|study, ~1|obs, ~1|species), test = "t", data = data)
  
  robust_model1.5_2 <- robust(model1.5_2, cluster = data$study, vcov = "CR2")
  
  predict(robust_model1.5, newmods = newdata)

```
# Methods

#### Meta-analysis
We analysed effect size data using the *metafor* @Metafor (vers 2.4.0) package in R @R (vers 4.0.5). To estimate the overall effect of male-harm on female fitness we first fit multi-level meta-analytic models (intercept only) @nakagawa2012methodological. Overall, we collected between `r n_eff_study[1]` to `r n_eff_study[2]` effect sizes per study. To control for sources of non-independence, we included study and species-level random effects @Noble2017. We also fit a model that included a species-level random effect with a phylogenetic correlation matrix derived using the Open Tree of Life Database @rotl. We used Grafen's method @Grafen to derive branch lengths using the R package *ape* @ape (vers 5.4.1). Overall, a model containing only a species-level random effect variance was better supported than a model that estimated a phylogenetic variance ($\Delta_{AIC_{c}}$ = `r dAICc`). As such, we did not include phylogeny in our models. Study and species-level random effects cannot account for additional sources of within-study non-independence, such as effect sizes derived from common treatment groups or effect sizes derived from different traits measured on the same individuals @Noble2017. We therefore applied robust variance estimators (RVEs) to correct standard errors from our models and ensure that our results were robust. RVEs have been shown to be robust estimators of standard errors from meta-analytic models when effect sizes within studies are correlated. In addition, one does not need to assume or specify how such effects are correlated @Song2021; @NakagawaEcology, making them easier to apply. 

Using our MLMA models we estimated effect size heterogenity as $I^2$ @HigginsThompson; @nakagawa2012methodological. $I^2_{study}$ and $I^2_{species}$ were the proportion of effect size variance over total variance as a result of between study and species effects, respectively. $I^2_{total}$ was calculated as the proportion of total effect size variance after accounting for, or removing, total sampling variance. 

We explored drivers of effect size heterogenity using multi-level meta-regression (MLMR) models. Our models included fixed effects (i.e., moderators) that we *a priori* predicted would impact female fitness. More specifically, we predicted that the intensity of sexual selection and sexual conflict would impact how much harm males did to females. To test these predictions, we included an index of sexual size dimorphism (SSD), which involved taking the log transfomed ratio between male body size to female body size for the species (i.e.,  $log \left( \frac{Male_{body size}}{Female_{bodysize}} \right)$, hereafter referred to as SSD). Positive SSD values indicate species with larger males compared to females, whereas negative SSD values indicate speceis where females are larger than males. While this does not directly measure the intensity of sexual selection, it is a proxy for it, and has been used in numerous meta-analyses in the past (CITE). 

In addition to SSD, we also categorised effect sizes as having come from species with different types of male harm. These include species with direct male harm (i.e., species with traumatic insemination) as well as species with indirect male harm (i.e., species that harm females through harrassment). There are also a number of species where it is clear both direct and indirect forms of male harm exist. Given that MLMR models assume homogeneity of variances across the levels of categorical moderators, and this assumption appeared to violated when visually inspecting the data (Figure \@ref(fig:maleharm)), we also fit a model that assumed heterogeneous residual variance across the different levels of male harm type moderator (i.e., different residual variance for 'Both', 'Direct' and 'Indirect' male harm type). We compared this model to a homogeneous variance model using $AIC_{c}$. Overall, the heterogeneous variance model did not improve overall fit ($\Delta_{AIC_{c}}$ = `r d_aicc_het`), and so, we report on the model assuming homogeneity of variance. 

#### Publication Bias

Publication bias results when studies with lower statistical power that find opposite patterns to the predicted effects (i.e., male harm increases female fitnes) go unpublished. This can result in effects being upwardly biased overall. Evidence for publication bias can be roughly detected by inspecting a funnel plot for funnel asymmetry. However, any asymmetry identified may simply be the result of high effect size heterogenity. As such, to more formally test for publication bias we used a new method that relies on fitting a MLMR model accounting for all the moderators available to explain variation in effects (i.e., all random and fixed effects). Using this model, we also include effect size sampling variance as a moderator @NakagawaPubBias. This apporach has the benefit of being a formal way to both statistically test for publication bias (while accounting for as much effect size heterogeneity as possible) and correcting for it; providing a sensitivity analysis on how the effect is expected to change if we were to hypothetically observe the missing effects @NakagawaPubBias. It is still important to note that this corrected overall mean should be interpreted with caution. We can never know exactly how many studies, if any, are missing. As such, these shoud be viewed as a sensitivity analysis. 

# Results

Overall, we collected effect sizes for a total of `r length(unique(data$species))` species from `r length(unique(data$study))` studies. Unsurprisingly, invertebrates (classes: Insecta, Gastropoda, Malacostraca, Arachnida, Clitellata and Secernentea) made up most of the data (`r (table(inverts$insect)[2] / sum(table(inverts$insect)))*100`%). We obtained `r table(data$Harm_type)[2]` effect sizes from manipulations on species that resulted in direct harm (e.g., traumatic insemination), whereas `r table(data$Harm_type)[3]` effects came from studies on species that manipulated indirect harm to females (e.g., mating rate and harassment). A total of `r table(data$Harm_type)[1]` effect sizes were from experiments where females received both direct and indirect harm from male matings. 

Across all species, we obtained `r table(data$Gestation)[1]` effects from `r parity[1,2]` oviparous species, and `r table(data$Gestation)[2]` effects from `r parity[2,2]` viviparous species. Unfortunately, effect sizes from viviparous species were all taken from studies on fish species with indirect male harm. As such, we analyzed only 'harm type' and an index of sexual size dimorphism.

#### Manipulating direct and indirect female harm negatively impacts female fitness

Experimentally manipulating female harm resulted in a strong decrease in female fitness overall (i.e., positive effect size with control group females having higher fitness than treatment groups: `r model1.1$beta`, 95% CI: `r model1.1$ci.lb` to `r model1.1$ci.ub`, $n_{effects}$ = `r model1.1$k.all`, $n_{study}$ = `r model1.1$s.nlevels[1]`). This strong effect held even when accounting for within-study non-independence (Meta-analytic mean using Robust Variance Estimator: `r robust$beta`, 95% CI: `r robust$ci.lb` to `r robust$ci.ub`). However, visual inspection of funnel plot asymmetry suggested evidence for publication bias (i.e., missed effects sizes with low precision when female harm was worse in control treatments) (Figure \@ref(fig:funnel)). Evidence for publication bias was confirmed through the identification of a significant slope between effect size and effective sample size ($\beta$ = `r model1.1_pub$beta[2]`, 95% CI: `r model1.1_pub$ci.lb[2]` to `r model1.1_pub$ci.ub[2]`), and this held true when accounting for heterogenity using meta-regression models ($\beta$ =`r model1.1_pub_full$beta[2]`, 95% CI: `r model1.1_pub_full$ci.lb[2]` to `r model1.1_pub_full$ci.ub[2]`). Correcting for the possibility of missing studies resulted in the overall meta-analytic mean effect size being indistinguisable from zero (Corrected meta-analytic mean: `r model1.1_pub$beta[1]`, 95% CI: `r model1.1_pub$ci.lb[1]` to `r model1.1_pub$ci.ub[1]`). It is important recognise that the corrected meta-analytic mean is simply a sensitivity analysis. We cannot know for certain whether publication bias treuly exists, and if so, how many missing studies exist.

When accounting for sampling variance there was high effect size heterogeneity ($I^2_{Total}$ = `r hetero_table$I2_Est.[nrow(hetero_table)]`, 95% CI: `r hetero_table[nrow(hetero_table), "2.5% CI"]` to `r hetero_table[nrow(hetero_table), "97.5% CI"]`) with most variance being the result of between study ($I^2_{Study}$ = `r hetero_table$I2_Est.[1]`, 95% CI: `r hetero_table[1, "2.5% CI"]` to `r hetero_table[1, "97.5% CI"]`) and between species ($I^2_{Species}$ = `r hetero_table$I2_Est.[3]`, 95% CI: `r hetero_table[3, "2.5% CI"]` to `r hetero_table[3, "97.5% CI"]`) effects. The trait type and phylogeny explained much less variation overall ($I^2_{Trait}$ = `r hetero_table$I2_Est.[2]`, 95% CI: `r hetero_table[2, "2.5% CI"]` to `r hetero_table[2, "97.5% CI"]`; $I^2_{Phylogeny}$ = `r hetero_table_phylo$I2_Est.[5]`, 95% CI: `r hetero_table_phylo[5, "2.5% CI"]` to `r hetero_table_phylo[5, "97.5% CI"]`). 

```{r funnel, fig.height=5, fig.width=16, fig.cap="A) Funnel plot of effect size as a function of precision (i.e., inverse of sampling standard error). B) orchaRd plot of the overall meta-analytic mean efect size, 95% confidnece intervals (thick black bars) and 95% prediction intervals (whiskers)"}
p1 <- ggplot(data, aes(x = SMDH, y = 1 / sqrt(v_SMDH), xmin = -6, xmax = 6)) +
geom_point(aes(colour = class)) +
labs(x = "SMDH", 
	 y = TeX("Precision $\\left(\\frac{1}{\\sqrt{v_{SMDH}}}\\right)$"),
	 colour = "Class") +
scale_color_grey() + 
#scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9")) + 
theme_bw() 

p2 <- orchard_plot(model1.1, mod = "Int", xlab = "SMDH") + scale_colour_manual(values = "grey") + scale_fill_manual(values = "red")

p1 + p2 + plot_annotation(tag_levels = c('A', 'B'))

```

```{r pretty_table}

autonum <- officer::run_autonum(seq_id = "tab", pre_label = "Table 1", bkm_all = TRUE)
ft <- flextable(table1)
ft <- set_caption(ft,  caption = "Effect size", autonum = autonum)
ft %>%
  compose(part = "header", j = "n", value = as_paragraph("n", as_sub("effects"))) %>%
  compose(part = "header", j = "std", value = as_paragraph("n", as_sub("studies"))) %>%
  compose(part = "header", j = "spp", value = as_paragraph("n", as_sub("species"))) %>%
  compose(part = "header", j = "est", value = as_paragraph("Meta-analytic mean")) %>%
  compose(part = "header", j = "CI", value = as_paragraph("95% CI")) %>%
  compose(part = "header", j = "PI", value = as_paragraph("95% PI")) %>%
  compose(part = "header", j = "i2_stdy", value = as_paragraph("I", as_sup("2"), as_sub("study"))) %>%
  compose(part = "header", j = "i2_trait", value = as_paragraph("I", as_sup("2"), as_sub("trait"))) %>%
  compose(part = "header", j = "i2_species", value = as_paragraph("I", as_sup("2"), as_sub("species"))) %>%
  compose(part = "header", j = "i2_tot", value = as_paragraph("I", as_sup("2"), as_sub("total")))
  

```

#### Negative effects on fitness depend on the type of harm done to females

Male harm type impacted the overall magnitude of effects. 

```{r maleharm, fig.width=6, fig.height=4.5}




ggplot(data, aes(x = Harm_type, y = SMDH, size = 1/sqrt(v_SMDH), fill = Harm_type, colour = Harm_type)) + geom_violin(alpha = 0.2) + geom_point() + 
  geom_jitter(width = 0.1) + 
   	#ggplot2::geom_errorbarh(aes(xmin = lowerPR, xmax = upperPR),  height = 0, show.legend = FALSE, size = 0.5, alpha = 0.6) +
	  	# 95 %CI: branches
	  #	ggplot2::geom_errorbarh(aes(xmin = lowerCL, xmax = upperCL),  height = 0, show.legend = FALSE, size = 1.2) +
	  #	ggplot2::geom_vline(xintercept = 0, linetype = 2, colour = "black", alpha = alpha) + 
      theme_bw() + 
		theme(legend.background = element_blank(),
			           legend.key = element_blank()) + 
  labs(x = "Harm Type", y = "SMDH", size = TeX("Precision $\\left(\\frac{1}{\\sqrt{v_{SMDH}}}\\right)$")) +
  scale_x_discrete(labels = c("Both", "Direct", "Indirect")) +
  guides(size = guide_legend(override.aes = list(linetype = 0))) + 
   scale_colour_discrete(guide = FALSE) +
  scale_fill_discrete(guide = FALSE) + 
  #ggplot2::annotate('text', x = (max(data$yi) + (max(data$yi)*0.10)), y = (seq(1, group_no, 1)+0.3), label= paste("italic(k)==", mod_table$K), parse = TRUE, hjust = "right", size = 3.5)
```

#### Female fitness is less compromised in species with reversed sexual size dimorphism (SSD) 

Species where females are larger than males (i.e., negative SSD) are less impacted by sexual conflict compared to spcies where males and females are closer in size or males are larger (i.e., SSD > 0) (z-transformed $\beta_{SSD}$ = `r model1.3$beta[2]`, 95% CI = `r model1.3$ci.lb[2]` to `r model1.3$ci.ub[2]`, Figure \@ref(fig:SSD) , $R^2_{marginal}$ = `r r2_SSD[1]*100`% of effect size variation).

```{r SSD, fig.width=6, fig.height=4.5, fig.cap="Sex dimorphism"}
p3 = ggplot(data, aes(x = SSD_lnRR, y = SMDH, size = 1/sqrt(v_SMDH))) + 
    geom_point() + 
      theme_bw() + 
  labs(x = "Sexual Size Dimorphism (SSD) Index", 
	     y = "SMDH",
	  size = TeX("Precision $\\left(\\frac{1}{\\sqrt{v_{SMDH}}}\\right)$")) +
	guides(size = guide_legend(direction = "vertical"))

p3
```

# References