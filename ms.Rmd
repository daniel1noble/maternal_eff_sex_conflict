---
  title: "Methods and Results"
  author: 
  date: "`r Sys.Date()`"
  bibliography: refs.bib
  csl: pnas.csl
  output: 
    bookdown::word_document2:
      toc: no
      toc_depth: 6
      number_sections: false
      tab_caption: yes
      fig_caption: yes
      reference_docx: template.docx
    bookdown::html_document2:
      code_folding: hide
      number_sections: no
      toc: yes
      toc_depth: 6
      toc_float: yes
  editor_options: 
    chunk_output_type: console
---
```{r setup, include=FALSE}
  knitr::opts_chunk$set(echo = FALSE, cache = FALSE, message = FALSE, warning = FALSE)
  ## numbers >= 10^5 will be denoted in scientific notation,      ## numbers >= 10^5 will be denoted in scientific notation,
    ## and rounded to 2 digits      ## and rounded to 2 digits
    options(digits = 2)
```

```{r loadpackages, echo = FALSE, results = "hide"}
devtools::install_github("daniel1noble/orchaRd", force = TRUE)
devtools::install_github("daniel1noble/metaAidR", force = TRUE)

  pacman::p_load(tidyverse, metafor, brms, orchaRd, ape, phytools, metaAidR, orchaRd, gt, kableExtra, flextable, patchwork, latex2exp, MuMIn, equatiomatic, magrittr, data.table)
eval(metafor:::.MuMIn)
```

```{r loaddata, echo = FALSE, results = "hide"}
################
# Tree
################
      source("./R/func.R")  
      data <- read.csv("./data/meta_data.csv")
      data <- data %>% 
              mutate(species2 = species, 
                     zSSD = scale(SSD_lnRR),
                     sex_life = log(M_lifespan / F_lifespan))
  
  # Bring in and prune tree
       tree <- read.tree("./phylogeny/tree")
       tree$tip.label <- gsub("_", " ", tree$tip.label)
  phylogeny <- vcv(tree, corr=TRUE)

  # Summary statistics for the results
  inverts <- data %>% 
             mutate(insect = ifelse(class %in% c("Insecta", "Gastropoda", "Malacostraca", "Arachnida", "Clitellata (Phylum Annelida)",  "Secernentea (Phylum Nematoda)"), 1,0))

  parity <- data %>% group_by(species) %>% summarise(parity = unique(Gestation)) %>% group_by(parity) %>% summarise(n=n())
  
  # Number of effects per study
  n_eff_study <- data %>%
                  group_by(study) %>%
                  summarise(n = n())
  n_eff_study <- range(n_eff_study$n)

###################
# Multilevel Meta-analytic Models (intercept only), plus robust variance estimation test.
###################
  
  model1.1 <- rma.mv(SMDH ~ 1, V = data$v_SMDH, 
                     random = list(~1|study, ~1|variable, ~1|species, ~1|obs),  dfs = "contain", test = "t", data = data)
    robust <- robust(model1.1, cluster = data$study, vcov = "CR2")
  
  model1.2 <- rma.mv(SMDH ~ 1, V = data$v_SMDH, 
                     random = list(~1|study, ~1|variable, ~1|species, ~1|species2, ~1|obs), R = list(species2 = phylogeny),  dfs = "contain", test = "t", data = data)
  
   aics <- AICc(model1.2, model1.1) # Phylogeny explains very little variation; model without phylogeny better supported, even if slightly. Just keep species in model
  dAICc <- max(aics$AICc) - min(aics$AICc)

# Table 1: Effect, confidence intervals, prediction intervals, heterogeneity
   hetero_table <- metaAidR::I2(model1.1, v = data$v_SMDH, obs = "obs") # Same as orchaRd::i2_ml(model1.1)    
   hetero_table_phylo <- metaAidR::I2(model1.2, v = data$v_SMDH, phylo = "species2", obs = "obs") # Same as orchaRd::i2_ml(model1.1)    
         table1 <- make_table(robust, heteroTable = hetero_table)

        # Just some model checks
         checks = FALSE
        
         if(checks){
           hist(residuals(model1.1))
        
           cd.model1.1 <- cooks.distance(model1.1)
           plot.cook(cd.model1.1, model1.1, vals = "obs")
           
           vals <- plot.cook(cd.model1.1, model1.1, vals = "obs", type = "vals")
           
           # results highly robust to outliers removed. Effect size strength increases
           model1.1_refit <- rma.mv(SMDH ~ 1, V = data$v_SMDH, 
                     random = list(~1|study, ~1|variable, ~1|species, ~1|obs), test = "t", data = data[!data$obs %in% vals,])
         }
         
###################
# Publication bias. Based on funnel plot, it looks like pub bias. Correct effect as a sensitivity analysis
###################
  
     data$inv_n_eff <- with(data, (N_C + N_T) / (N_C * N_T))
  
       model1.1_pub <- rma.mv(SMDH ~ sqrt(inv_n_eff), V = data$v_SMDH, 
                              random = list(~1|study, ~1|variable, ~1|species, ~1|obs),  dfs = "contain", test = "t", data = data)
  
  model1.1_pub_full <- rma.mv(SMDH ~ sqrt(inv_n_eff) + SSD_lnRR + Harm_type, V = data$v_SMDH, 
                              random = list(~1|study, ~1|variable, ~1|species, ~1|obs), dfs = "contain", test = "t", data = data)
   model1.1_pub_full_het <- rma.mv(SMDH ~ sqrt(inv_n_eff) + SSD_lnRR + Harm_type, V = data$v_SMDH, 
                              random = list(~1|study, ~1|variable, ~1|species, ~Harm_type|obs), rho = 0, 
                              str = "HCS",  dfs = "contain", test = "t", data = data)
      AICc(model1.1_pub_full, model1.1_pub_full_het) # Checked that k = 120 for both models, using same dataset. Basically the same results so simplify model.

###################
# Meta-regressions
###################
  ###############
      # SSD
  ################
  # Marginalised model. Just easier to get slope
  model1.3 <- rma.mv(SMDH ~ zSSD, V = data$v_SMDH, 
                     random = list(~1|study, ~1|species, ~1|obs),  dfs = "contain", test = "t", data = data[complete.cases(data$zSSD),])
  robust_model1.3 <- robust(model1.3, cluster = data[complete.cases(data$zSSD),"study"])
  
  # Use raw SSD for plotting, so we can plot raw data, which is easier to interpret
  model1.3_nonZ <- rma.mv(SMDH ~ SSD_lnRR, V = data$v_SMDH, 
                     random = list(~1|study, ~1|species, ~1|obs),  dfs = "contain", test = "t", data = data)
  robust_model1.3_nonZ <- robust(model1.3_nonZ, cluster = data$study)
  
        r2_SSD = r2_ml(model1.3)

  # Just some model checks.
    if(checks){
           hist(residuals(model1.3))
        
           cd.model1.3 <- cooks.distance(model1.3)
           plot.cook(cd.model1.3, model1.3, vals = "obs")
           vals <- plot.cook(cd.model1.3, model1.3, vals = "obs", type = "vals")
           
           # Removing outliers decrease zSSD effect by 0.10, but still non-significant/
           model1.3_refit <- rma.mv(SMDH ~ zSSD, V = data$v_SMDH, 
                     random = list(~1|study, ~1|species, ~1|obs), test = "t", data = data[!data$obs %in% vals,])
    }
        
  ###############
      # Harm type
  ################
  # Marginalised Harm type        
  model1.4 <- rma.mv(SMDH ~ Harm_type, V = data$v_SMDH, 
                     random = list(~1|study, ~1|species, ~1|obs),  dfs = "contain", test = "t", data = data[complete.cases(data$Harm_type),])
  robust(model1.4, cluster = data[complete.cases(data$Harm_type),"study"])

  male_harm_r2 = r2_ml(model1.4)
  
  # Just some model checks.
    if(checks){
           hist(residuals(model1.4))
        
           cd.model1.4 <- cooks.distance(model1.4)
           plot.cook(cd.model1.4, model1.4, "obs")
           vals <- plot.cook(cd.model1.4, model1.4, "obs", type = "vals")
          
         model1.4_refit <- rma.mv(SMDH ~ Harm_type, V = data$v_SMDH, 
                     random = list(~1|study, ~1|species, ~1|obs),  dfs = "contain", test = "t", data = data[!data$obs %in% vals,])    
           
        }
  ###############
      # Harm type & SSD
  ################
  # Model that contains harm type and SSD. Harm type appears to have different variances, so I'll check whether it is safe to assume homogeneity of variance across groups
  model1.5 <- rma.mv(SMDH ~  Harm_type + zSSD, V = data$v_SMDH, 
                     random = list(~1|study, ~1|obs, ~1|species),  dfs = "contain", test = "t", 
                     method = "ML", data = data[complete.cases(data$Harm_type, data$zSSD),])
  model1.5_inter <- rma.mv(SMDH ~  Harm_type + zSSD + Harm_type:zSSD, V = data$v_SMDH, 
                     random = list(~1|study, ~1|obs, ~1|species),  dfs = "contain", test = "t", 
                     method = "ML", data = data)
  
  # Does SSD effect vary by harm type. No evidence for interaction
   aicc_ssd_interact <- AICc(model1.5, model1.5_inter)
  dAICc_ssd_interact <- max(aicc_ssd_interact$AICc) - min(aicc_ssd_interact$AICc)
  
  # Update models with REML now
        model1.5 <- update(model1.5, method = "REML" )
  
  # Non Z transform
  model1.5_nonZ <- rma.mv(SMDH ~ Harm_type + SSD_lnRR, V = data$v_SMDH, 
                     random = list(~1|study, ~1|species, ~1|obs), dfs = "contain", test = "t", data = data)
  robust_model1.5_nonZ <- robust(model1.5_nonZ, cluster = data$study)
  
  model1.6 <- rma.mv(SMDH ~ Harm_type + zSSD, V = data$v_SMDH, 
                     random = list(~1|study, ~(1 + Harm_type)|obs, ~1|species), 
                     rho = 0, struc = "HCS",  dfs = "contain", test = "t", data = data)
  
  # Compare AICc for each model
    aicc_het <- AICc(model1.5, model1.6)
  d_aicc_het <- max(aicc_het$AICc) - min(aicc_het$AICc) # Delta suggests homogeneity model better
  
  # Check robustness of results using sandwich estimator
  robust_model1.5 <- robust(model1.5, cluster = data[complete.cases(data$Harm_type, data$zSSD),"study"], vcov = "CR2")
  
  # Just some model checks.
   if(checks){
           hist(residuals(model1.5))
        
           cd.model1.5 <- cooks.distance(robust_model1.5)
           plot.cook(cd.model1.5, robust_model1.5, "obs")
           vals <- plot.cook(cd.model1.5, robust_model1.5, "obs", type = "vals")
          
         model1.5_refit <- rma.mv(SMDH ~ Harm_type + zSSD, V = data$v_SMDH, 
                     random = list(~1|study, ~1|species, ~1|obs), test = "t", data = data[!data$obs %in% vals,])    
         # But very clear outlier is 136 so remove this first
         model1.5_refit <- rma.mv(SMDH ~ Harm_type + zSSD, V = data$v_SMDH, 
                     random = list(~1|study, ~1|species, ~1|obs), test = "t", data = data[!data$obs %in% 136,])    
   }
  
  # Now reparameterize model
  model1.5_2 <- rma.mv(SMDH ~ 0 + Harm_type + zSSD, V = data$v_SMDH, 
                     random = list(~1|study, ~1|obs, ~1|species), dfs = "contain", test = "t", data = data)
  
     robust_model1.5_2 <- robust(model1.5_2, cluster = data$study)
     
  robust_model1.5_2_PI <- pred_interval(model1.5_2, c(5.1796, -0.6908, 3.0189, 1.9679))
  
  # Add N
  n <- data %>% group_by(Harm_type) %>% summarise(n = n(), nstdy = length(unique(study)))
  n[4,c(2,3)] <- t(c(dim(data)[1], with(data, length(unique(study)))))
  robust_model1.5_2_PI$n <- n$n
  robust_model1.5_2_PI$nstudy <- n$nstdy

  ###############
      # Sperm Intensity
  ################
  # Sperm competition intensity. Use ML because comparing fixed effects. 
  sperm_data <- data %>% filter(!SCR.SCI == "hermaphrodite" & !is.na(zSSD))

  model1.7_inetr <- rma.mv(SMDH ~  SCR.SCI*zSSD, V = sperm_data$v_SMDH, 
                     random = list(~1|study, ~1|obs, ~1|species), dfs = "contain", test = "t", 
                     method = "ML", data = sperm_data)
    
  model1.7 <- rma.mv(SMDH ~  SCR.SCI + zSSD, V = sperm_data$v_SMDH, 
                     random = list(~1|study, ~1|obs, ~1|species), dfs = "contain", test = "t", 
                     method = "ML", data = sperm_data)
  
  # Check for interaction
   # Compare AICc for each model
    aicc_1.7 <- AICc(model1.7_inetr, model1.7)
  d_aicc_1.7 <- max(aicc_1.7$AICc) - min(aicc_1.7$AICc) # Main effect model better supported
  
  # Robust
         model1.7 <- update(model1.7, method = "REML")
  robust_model1.7 <- robust(model1.7, cluster = sperm_data$study, vcov = "CR2")
  
  
  # Fit het variance model
  model1.7_het <- rma.mv(SMDH ~ SCR.SCI + zSSD, V = sperm_data$v_SMDH, 
                     random = list(~1|study, ~(1 + SCR.SCI)|obs, ~1|species), 
                     rho = 0, struc = "HCS", test = "t", data = sperm_data)
  
  aicc_1.7_het <- AICc(model1.7_het, model1.7)
   d_aicc_1.7_het <- max(aicc_1.7_het$AICc) - min(aicc_1.7_het$AICc)
   
  # Just some model checks.
    if(checks){
           hist(residuals(model1.7))
        
           cd.model1.7 <- cooks.distance(model1.7)
           plot.cook(cd.model1.7, model1.7, "obs")
           obs <- plot.cook(cd.model1.7, model1.7, "obs",type = "vals")

      # Results are pretty similar without these rows with high Cooks D
      model1.7_refit <- rma.mv(SMDH ~  SCR.SCI + zSSD, V = sperm_data$v_SMDH, 
                     random = list(~1|study, ~1|obs, ~1|species), dfs = "contain", test = "t", 
                     method = "ML", data = sperm_data[!sperm_data$obs %in% obs,])
        }
   
  model1.7_reparam <- rma.mv(SMDH ~ 0 +  SCR.SCI + zSSD, V = sperm_data$v_SMDH, 
                     random = list(~1|study, ~1|obs, ~1|species), test = "t", 
                     method = "REML", data = sperm_data)
  robust_model1.7_reparam <- robust(model1.7_reparam, cluster = sperm_data$study, vcov = "CR2")
  
  ###############
      # Lifespan
  ################
  # Sex differences in lifespan
    model1.8 <- rma.mv(SMDH ~ sex_life, V = data$v_SMDH, 
                       random = list(~1|study, ~1|obs, ~1|species), dfs = "contain", test = "t", 
                       method = "REML", data = data)
    robust_model1.8 <- robust(model1.8, cluster = data$study, vcov = "CR2")
    
    model1.9 <- rma.mv(SMDH ~ sex_life + zSSD + Harm_type, V = data$v_SMDH, 
                       random = list(~1|study, ~1|obs, ~1|species), dfs = "contain", test = "t", 
                       method = "REML", data = data)
    robust_model1.9 <- robust(model1.9, cluster = data$study, vcov = "CR2")
    
  # Female lifespan
    model1.10 <- rma.mv(SMDH ~ scale(F_LRS), V = data$v_SMDH, 
                       random = list(~1|study, ~1|obs, ~1|species), dfs = "contain", test = "t", 
                       method = "REML", data = data)
    robust_model1.10 <- robust(model1.10, cluster = data$study, vcov = "CR2")
    
    model1.11 <- rma.mv(SMDH ~ scale(F_LRS) + Harm_type + zSSD, V = data$v_SMDH, 
                       random = list(~1|study, ~1|obs, ~1|species), dfs = "contain", test = "t", 
                       method = "REML", data = data)
    robust_model1.11 <- robust(model1.11, cluster = data$study, vcov = "CR2")
    
  
  ###############
      # Final tables
  ################
  # Tables
                n1.7 <- sperm_data %>% group_by(SCR.SCI) %>% summarise(n = n(), nstdy = length(unique(study)), moderator = unique(SCR.SCI))
      n1.7[3,c(2,3)] <- t(c(dim(data)[1], with(data, length(unique(study)))))
  robust_model1.7_PI <- pred_interval(robust_model1.7_reparam, c(4.404, 1.88, 2.49)) # Ignore PIs not used and not correct
  robust_model1.7_PI <- cbind(robust_model1.7_PI, n1.7)
  
  
```
# Methods
#### Standardised Effect Size Measure
We used the standardised mean difference with a small sample correction (i.e., Hedges' *g*) as our measure of effect size comparing female fitness measures across experimental treatments. To correct for the possibility that population variances in the two treatments differ, we made use of a corrected version of Hedges' *g* that controls for heteroscedastic population variances (hereafter called SMDH; [@Bonnet2008; @Bonnett2009]). Effect sizes were calculated by subtracting the control group mean from the treatment group mean and dividing by the pooled standard deviation. As such, positive effect sizes indicate that female 'fitness/traits' in control groups was higher than female 'fitness/traits' in treatment groups. 

#### Meta-analysis
We analysed effect size data using the *metafor* @Metafor (vers. `r utils::packageVersion("metafor")`) package in R @R (vers. `r paste0(R.Version()$major, ".", R.Version()$minor)`). To estimate the overall effect of male-harm on female fitness we first fit multi-level meta-analytic models (intercept only) @nakagawa2012methodological. We plotted overall meta-analytic means using the orchard plot package @NakaOrchard (vers. `r utils::packageVersion("orchard")`). Overall, we collected between `r n_eff_study[1]` to `r n_eff_study[2]` effect sizes per study. To control for sources of non-independence, we included study and species-level random effects @Noble2017. We also fit a model that included a species-level random effect with a phylogenetic correlation matrix derived using the Open Tree of Life Database @rotl (vers. `r utils::packageVersion("rotl")`). We used Grafen's method @Grafen to calculate branch lengths using the R package *ape* @ape (vers. `r utils::packageVersion("ape")`). Overall, a model containing only a species-level random effect variance was better supported than a model that estimated a phylogenetic variance ($\Delta_{AIC_{c}}$ = `r dAICc`). As such, we did not include phylogeny in our models. 

Study and species-level random effects cannot account for additional sources of within-study non-independence, such as effect sizes calculated using common treatment groups or for different traits measured on the same individuals @Noble2017. We therefore applied robust variance estimators (RVEs) to correct standard errors from our models. RVEs have been shown to be excellent estimators of standard errors from meta-analytic models when effect sizes within studies are correlated. In addition, one does not need to assume, or specify, how such effects are correlated [@Song2021; @NakagawaEcology], making them easier to apply. 

Using our MLMA models we also calculated effect size heterogeneity using $I^2$ [@HigginsThompson; @nakagawa2012methodological]. $I^2_{study}$ and $I^2_{species}$ are defined as the proportion of effect size variance over total variance as a result of between study and species effects, respectively.In contrast, $I^2_{total}$ was calculated as the proportion of total effect size variance after accounting for, or removing, total sampling variance. 

We explored drivers of effect size heterogeneity using multi-level meta-regression (MLMR) models. Our models included fixed effects (i.e., moderators) that we *a priori* predicted would impact female fitness. More specifically, we predicted that the intensity of sexual selection and sexual conflict would affect how much harm males did to females. To test these predictions, we included an index of sexual size dimorphism (SSD), which involved taking the log transformed ratio between male body size to female body size for the species (i.e.,  $log \left( \frac{Male_{body size}}{Female_{bodysize}} \right)$, hereafter referred to as SSD). Positive SSD values indicate species with larger males compared to females, whereas negative SSD values indicate species where females are larger than males. While this does not directly measure the intensity of sexual selection it is an intuitive, interpretable metric that is normally distributed around zero [@Harrison2022; @Lovitch1992]. 

In addition to SSD, we also categorised effect sizes as having come from species with different types of male harm and sperm competition intensity (see moderators section). These included species with direct male harm (i.e., species with traumatic insemination) as well as species with indirect male harm (i.e., species that harm females through harassment). There are also a number of species where it is clear both direct and indirect forms of male harm exist. We also fit separate models to a two-level categorical moderator describing the sperm competition intensity of the species (i.e, "high" or "low"). In both these models, we controlled for SSD index, but included z-transformed SSD, such that meta-analytic means in each categorical moderator are for species of average SSD. We also accounted for the possibility that SSD might vary depending on the specific harm type and sperm competition intensity (i.e., interaction between SSD and Harm type and Sperm competition intensity). We evaluated support for interactions by comparing a model including the interaction to a model without it, comparing $AIC_{c}$ between the two models. We chose the model with the lowest $AIC_{c}$ if they differed by greater than 2, otherwise, we choose the most parsimonious model. All models comparing fixed effects were fit with maximum likelihood for model comparison of fixed effect structure, and then subsequently re-fit with restricted maximum likelihood when the fixed effect structure was identified.

Given that MLMR models assume homogeneity of variances across the levels of categorical moderators, and this assumption appeared to violated when visually inspecting the data (Figure \@ref(fig:maleharm)), we also fit a model that assumed heterogeneous residual variance across the different levels of male harm type moderator (i.e., different residual variance for 'Both', 'Direct' and 'Indirect' male harm type). We compared this model to a homogeneous variance model using $AIC_{c}$. Overall, the heterogeneous variance models did not improve overall fit (Harm Type: $\Delta_{AIC_{c}}$ = `r d_aicc_het`; Sperm Competition Intensity:  $\Delta_{AIC_{c}}$ = `r d_aicc_1.7_het`), and so, we report results from the homogeneity of variance models. 

#### Publication Bias

Publication bias results when studies with lower statistical power that find opposite patterns to the predicted effects (i.e., male harm increases female fitnes) go unpublished. This can result in effects being upwardly biased overall. Evidence for publication bias can be roughly detected by inspecting a funnel plot for funnel asymmetry. However, any asymmetry identified may simply be the result of high effect size heterogenity. As such, to more formally test for publication bias we used a new method that relies on fitting a MLMR model accounting for all the moderators available to explain variation in effects (i.e., all random and fixed effects). Using this model, we also include effect size sampling variance as a moderator @NakagawaPubBias. This apporach has the benefit of being a formal way to both statistically test for publication bias (while accounting for as much effect size heterogeneity as possible) and correcting for it; providing a sensitivity analysis on how the effect is expected to change if we were to hypothetically observe the missing effects @NakagawaPubBias. It is still important to note that this corrected overall mean should be interpreted with caution. We can never know exactly how many studies, if any, are missing. As such, these shoud be viewed as a sensitivity analysis. 

# Results

Overall, we collected effect sizes for a total of `r length(unique(data$species))` species from `r length(unique(data$study))` studies. Unsurprisingly, invertebrates (classes: Insecta, Gastropoda, Malacostraca, Arachnida, Clitellata and Secernentea) made up most of the data (`r (table(inverts$insect)[2] / sum(table(inverts$insect)))*100`%). We obtained `r table(data$Harm_type)[2]` effect sizes from manipulations on species that resulted in direct harm (e.g., traumatic insemination), whereas `r table(data$Harm_type)[3]` effects came from studies on species that manipulated indirect harm to females (e.g., mating rate and harassment). A total of `r table(data$Harm_type)[1]` effect sizes were from experiments where females received both direct and indirect harm from male matings. 

Across all species, we obtained `r table(data$Gestation)[1]` effects from `r parity[1,2]` oviparous species, and `r table(data$Gestation)[2]` effects from `r parity[2,2]` viviparous species. Unfortunately, effect sizes from viviparous species were all taken from studies on fish species with indirect male harm. As such, we analyzed only 'harm type' and an index of sexual size dimorphism.

#### Manipulating direct and indirect female harm negatively impacts female fitness

Experimentally manipulating female harm resulted in a strong decrease in female fitness overall (i.e., positive effect size with control group females having higher fitness than treatment groups: `r model1.1$beta`, 95% CI: `r model1.1$ci.lb` to `r model1.1$ci.ub`, $n_{effects}$ = `r model1.1$k.all`, $n_{study}$ = `r model1.1$s.nlevels[1]`). This effect held even when accounting for within-study non-independence (meta-analytic mean using Robust Variance Estimator: `r robust$beta`, 95% CI: `r robust$ci.lb` to `r robust$ci.ub`). Visual inspection of funnel plot asymmetry suggested evidence for publication bias (i.e., missed effects sizes with low precision when female harm was worse in control treatments) (Figure \@ref(fig:funnel)), which was confirmed through the identification of a significant slope between effect size and effective sample size ($\beta$ = `r model1.1_pub$beta[2]`, 95% CI: `r model1.1_pub$ci.lb[2]` to `r model1.1_pub$ci.ub[2]`). This result held true when accounting for heterogeneity using meta-regression models ($\beta$ =`r model1.1_pub_full$beta[2]`, 95% CI: `r model1.1_pub_full$ci.lb[2]` to `r model1.1_pub_full$ci.ub[2]`). Correcting for the possibility of missing studies resulted in the overall meta-analytic mean effect size being indistinguishable from zero (Corrected meta-analytic mean: `r model1.1_pub$beta[1]`, 95% CI: `r model1.1_pub$ci.lb[1]` to `r model1.1_pub$ci.ub[1]`). These findings suggest that additional empirical studies may change the overall magnitude of effects, possibly showing weaker effects then what is currently published, but our current state of knowledge suggests that female fitness is indeed compromised overall by male harm.

When accounting for sampling variance there was high effect size heterogeneity ($I^2_{Total}$ = `r hetero_table$I2_Est.[nrow(hetero_table)]`, 95% CI: `r hetero_table[nrow(hetero_table), "2.5% CI"]` to `r hetero_table[nrow(hetero_table), "97.5% CI"]`) with most variance being the result of between study ($I^2_{Study}$ = `r hetero_table$I2_Est.[1]`, 95% CI: `r hetero_table[1, "2.5% CI"]` to `r hetero_table[1, "97.5% CI"]`) and between species ($I^2_{Species}$ = `r hetero_table$I2_Est.[3]`, 95% CI: `r hetero_table[3, "2.5% CI"]` to `r hetero_table[3, "97.5% CI"]`) effects. The trait type and phylogeny explained much less variation overall ($I^2_{Trait}$ = `r hetero_table$I2_Est.[2]`, 95% CI: `r hetero_table[2, "2.5% CI"]` to `r hetero_table[2, "97.5% CI"]`; $I^2_{Phylogeny}$ = `r hetero_table_phylo$I2_Est.[5]`, 95% CI: `r hetero_table_phylo[5, "2.5% CI"]` to `r hetero_table_phylo[5, "97.5% CI"]`) (Table \@ref(tab:table1)). 

```{r funnel, fig.height=7.62500, fig.width=14.90278, fig.cap="A) Funnel plot of effect size as a function of precision (i.e., inverse of sampling standard error). B) orchaRd plot of the overall meta-analytic mean efect size, 95% confidnece intervals (thick black bars) and 95% prediction intervals (whiskers)"}
p1 <- ggplot(data, aes(x = SMDH, y = 1 / sqrt(v_SMDH), xmin = -6, xmax = 6)) +
geom_point(aes(colour = class), size = 3) +
labs(x = "SMDH", 
	 y = TeX("Precision $\\left(\\frac{1}{\\sqrt{v_{SMDH}}}\\right)$"),
	 colour = "Class") +
scale_color_grey() + 
#scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9")) + 
theme_bw() 

p2 <- orchard_plot(model1.1, mod = "1", group = "species", data = data, xlab = "SMDH") + 
      scale_colour_manual(values = "grey") + 
      scale_fill_manual(values = "red") +
      scale_y_discrete(labels = "")

p3 <- p1 + p2 + plot_annotation(tag_levels = c('A', 'B'))
p3
ggsave(plot = p3, filename = "fig1.png", width = 12, height= 5, path = "./output/figs", units = "in", device="png", dpi = 600)
```

```{r table1, tab.cap = "Number of effect sizes, studies and species along with overall meta-analytic mean (average SMDH) and 95% confidence (CI) and prediction intervals (PI). Heterogeneity estimates and 95% CI's are also provided for study, trait, species and total heterogeneity (excluding sampling variance)"}

#autonum <- officer::run_autonum(seq_id = "tab", pre_label = "Table 1", bkm_all = TRUE)
ft <- flextable::flextable(table1)
ft %>%
  flextable::compose(part = "header", j = "n", value = as_paragraph("n", as_sub("effects"))) %>%
  flextable::compose(part = "header", j = "std", value = as_paragraph("n", as_sub("studies"))) %>%
  flextable::compose(part = "header", j = "spp", value = as_paragraph("n", as_sub("species"))) %>%
  flextable::compose(part = "header", j = "est", value = as_paragraph("Meta-analytic mean")) %>%
  flextable::compose(part = "header", j = "CI", value = as_paragraph("95% CI")) %>%
  flextable::compose(part = "header", j = "PI", value = as_paragraph("95% PI")) %>%
  flextable::compose(part = "header", j = "i2_stdy", value = as_paragraph("I", as_sup("2"), as_sub("study"))) %>%
  flextable::compose(part = "header", j = "i2_trait", value = as_paragraph("I", as_sup("2"), as_sub("trait"))) %>%
  flextable::compose(part = "header", j = "i2_species", value = as_paragraph("I", as_sup("2"), as_sub("species"))) %>%
  flextable::compose(part = "header", j = "i2_tot", value = as_paragraph("I", as_sup("2"), as_sub("total"))) %>% 
  flextable::font(part = "header", font = "Times") %>% 
  flextable::font(part = "body", font = "Times") %>% 
  flextable::fit_to_width(max_width = 8)
  
```

#### Negative effects on fitness and the type of harm done to females

Male harm type appeared to impact the overall magnitude of effects explaining `r male_harm_r2[1]*100`% of effect size variance (Figure \@ref(fig:maleharm)). Species where mating results in both direct and indirect harm to females have males that significantly impact female fitness (overall meta-analytic mean: `r robust_model1.5_2$beta[1]`, 95% CI: `r robust_model1.5_2$ci.lb[1]` to `r robust_model1.5_2$ci.ub[1]`,  p = `r p_value(robust_model1.5_2$pval[1])`). Surprisingly, however, species with direct female harm only (i.e., traumatic insemination), showed a small and opposite effect on female fitness (overall meta-analytic mean: `r robust_model1.5_2$beta[2]`, 95% CI: `r robust_model1.5_2$ci.lb[2]` to `r robust_model1.5_2$ci.ub[2]`; Figure \@ref(fig:maleharm)), however, this effect did not differ significantly from zero (p = `r p_value(robust_model1.5_2$pval[2])`). While indirect male harm also resulted in a smaller overall meta-analytic mean relative to species with both, it was still significantly positive (overall meta-analytic mean: `r robust_model1.5_2$beta[3]`, 95% CI: `r robust_model1.5_2$ci.lb[3]` to `r robust_model1.5_2$ci.ub[3]`,  p = `r p_value(robust_model1.5_2$pval[3])`), and only marginally different than species with both direct and indirect male harm (Figure \@ref(fig:maleharm)). Regardless, differences among species exhibiting different types of female harm seemed to be driven primarily by
a single study (Taylor, 2008) on *Drosophila melanogaster* (very high Cook's distance). Removing this effect resulted in no significant difference between harm type categories. 


```{r maleharm, fig.width=11.56944, fig.height=7.62500, fig.cap="Distribution of effect sizes, overall meta-analytic mean estimates and 95% confidence intervals (CIs) across species with different types of male harm towards females. Total effect sizes (n) and total number of studies (k) are provided for each level of Male Harm Type. Relevant contrasts between meta-analytic means are provided, along with 95% CIs and significance of contrast. Note that this includes all data. Removing outlier point from single study results in no different between harm type categories. "}

# model results
rownames(robust_model1.5_2_PI) <- 1:dim(robust_model1.5_2_PI)[1]
robust_model1.5_2_PI$moderator <- c("both", "direct", "indirect", "SSD")
# remove last row
robust_model1.5_2_PI <- robust_model1.5_2_PI[1:3,]

# We'll use the contrast model to get what we need to plot stats above comparison bars

contrast1 <- paste0("$\\beta_{contrast}$ = ", round(robust_model1.5$beta[2], digit = 2), ", 95% CI:", round(robust_model1.5$ci.lb[2], digit = 2), " to ", round(robust_model1.5$ci.ub[2], digit = 2), ", $\\textbf{p ", p_value(robust_model1.5$pval[2]), "}$")

contrast2 <- paste0("$\\beta_{contrast}$ = ", round(robust_model1.5$beta[3], digit = 2), ", 95% CI:", round(robust_model1.5$ci.lb[3], digit = 2), " to ", round(robust_model1.5$ci.ub[3], digit = 2), ", p = ", p_value(robust_model1.5$pval[3]))

# When making this plot we are feeding in two different types of data. This can be a tad tricky because you need to understand how data is mapped. See nice explanation here:https://stackoverflow.com/questions/31069324/adding-points-from-other-dataset-to-ggplot2

harm_plot <- ggplot(data, aes(x = Harm_type, y = SMDH)) + 
              geom_violin(alpha = 0.2, aes(fill = Harm_type, colour = Harm_type)) + 
              #geom_point() + don't need this because we have geom_jitter. It will otherwise double plot points
              ylim(c(-2, 6.5)) + 
              geom_jitter(aes(x = Harm_type, y = SMDH, fill = Harm_type, colour = Harm_type, size = 1/sqrt(v_SMDH)),
                          width = 0.08, alpha = 0.2) + 
              theme_bw() + 
		          theme(legend.background = element_blank(),
			                     legend.key = element_blank()) + 
              labs(x = "Harm Type", 
                   y = "SMDH", 
                   size = TeX("Precision $\\left(\\frac{1}{\\sqrt{v_{SMDH}}}\\right)$")) +
              scale_x_discrete(labels = c("Both", "Direct", "Indirect")) +
              guides(size = guide_legend(override.aes = list(linetype = 0))) + 
              scale_colour_discrete(guide = FALSE) +
              scale_fill_discrete(guide = FALSE) + 
              annotate('text', x = (seq(1, 3, 1)), y = 6.45, 
                       label= paste0("italic(n)==", robust_model1.5_2_PI$n), parse = TRUE, size = 3.5) +     
              annotate('text', x = (seq(1, 3, 1)), y = 6.15, 
                       label= paste0("italic(k)==", robust_model1.5_2_PI$nstudy), parse = TRUE, size = 3.5) +     
        	  	# 95 %CI: branches
        	    geom_errorbar(data = robust_model1.5_2_PI,  aes(x = moderator, y = Est, ymin = lwr.CI, ymax = up.CI), 
        	                  height = 0, show.legend = FALSE, size = 0.5, width = 0.05) +
              geom_point(data = robust_model1.5_2_PI, aes(x = moderator, y = Est, colour= moderator), size = 5)+
              geom_segment(aes(x = 1, y = 4.8, xend = 2, yend = 4.8), arrow = arrow(length = unit(0.1, "cm"), angle = 90, end = "both")) + 
              geom_segment(aes(x = 1, y = 5.5, xend = 3, yend = 5.5), arrow = arrow(length = unit(0.1, "cm"), angle = 90, end = "both")) +
              #geom_segment(aes(x = 2, y = -1, xend = 3, yend = -1), arrow = arrow(length = unit(0.1, "cm"), angle = 90, end = "both"))
              annotate('text', x = 1 + ((2-1) / 2), y = 5, label = TeX(contrast1), size = 4) + 
              annotate('text', x = 1 + ((3-1) / 2), y = 5.7, label = TeX(contrast2), size = 4) 
              #annotate('text', x = 2 + ((2-1) / 2), y = -1, label = TeX(contrast3), size = 2.5)
ggsave(plot = harm_plot, filename = "fig2.png", path = "./output/figs", height = 7.416667, width = 13.805556, device = "png", dpi = 600)
harm_plot
```

#### Female fitness is more compromised when sexual size dimorphism is low 

As males and females of a species become more similar in size (i.e., increasing SSD index converging on 0) female fitness is more negatively impacted when increasing male harm (i.e., larger fitness decrease observed in treatment group or a more positive effect size) (unstandardised slope, $\beta_{SSD}$ = `r robust_model1.5_nonZ$beta[4]`, 95% CI = `r robust_model1.5_nonZ$ci.lb[4]` to `r robust_model1.5_nonZ$ci.ub[4]`,  $R^2_{marginal}$ = `r r2_SSD[1]*100`% of effect size variation; Figure \@ref(fig:SSD)). However, the magnitude of slope was marginally non-significant (p = `r p_value(robust_model1.5$pval[4])`). In addition, there was no evidence that the effect of SSD varied according to the type of male harm exhibited (i.e., no interaction between Harm Type and SSD; $\Delta_{AIC_{c}}$ =`r dAICc_ssd_interact`, with the main effects model having the lowest $AIC_{c}$). Interestingly, this pattern qualitatively appears to reverse in species where females are larger than males (i.e., SSD > 0; Figure \@ref(fig:SSD)), however, there is only one species where SSD is greater than 0 (i.e., *Idotea balthica*), making any concrete conclusions premature. 

```{r SSD, fig.width=11.56944, fig.height=7.62500, fig.cap="Relationship between index of sexual size dimorphism for species (log(male/female)) and effect sizes (i.e., Heteroscedastic Standardised Mean Differences (SMDH)). Note that we provide an estimate of stndardised slope (from a model with z-transformed SSD index), along with 95% CIs and significance. A slope from a model using unstandardised SSD index is plotted along with raw data for ease of interpretation and is provided in text."}
contrast3top <- paste0("Standardised $\\beta_{SSD}$ = ", round(robust_model1.5$beta[4], digit = 2)) 
contrast3bottom <- paste0("95% CI: ", round(robust_model1.5$ci.lb[4], digit = 2), " to ", round(robust_model1.5$ci.ub[4], digit = 2))
contrast3bottom2 <- paste0("p = ", p_value(robust_model1.5$pval[4]))

p3 = ggplot(data, aes(x = SSD_lnRR, y = SMDH, size = 1/sqrt(v_SMDH), colour = Harm_type)) + 
    geom_point(alpha = 0.6) + 
      theme_bw() + 
  labs(x = "Sexual Size Dimorphism (SSD) Index", 
	     y = "SMDH",
	  size = TeX("Precision $\\left(\\frac{1}{\\sqrt{v_{SMDH}}}\\right)$"),
	  colour = "Male Harm Type") +
  scale_colour_discrete(labels = c("Both", "Direct", "Indirect")) +
	guides(size = guide_legend(direction = "vertical")) +
  annotate('text', x = -0.4, y = 4.5, label = TeX(contrast3top), size = 5) +
  annotate('text', x = -0.4, y = 4.2, label = TeX(contrast3bottom), size = 5) +
  annotate('text', x = -0.4, y = 3.9, label = TeX(contrast3bottom2, italic = TRUE), size = 5) +
  geom_abline(intercept = robust_model1.3_nonZ$beta[1], slope = robust_model1.3_nonZ$beta[2]) # Note using model1.3 for plotting because this is marginalised across Harm_type. 

ggsave(plot = p3, filename = "fig3.png", path = "./output/figs", height = 7, width = 10, device = "png", dpi = 600)
p3
```


#### Male harm in species with high sperm competition intensity does not result in radically reduced female fitness

Species with higher sperm intensity exhibited a significant reduction in female fitness with higher male harm (overall meta-analytic mean: `r robust_model1.7_reparam$beta[1]`, 95% CI: `r robust_model1.7_reparam$ci.lb[1]` to `r robust_model1.7_reparam$ci.ub[1]`, p = `r p_value(robust_model1.7_reparam$pval[1])`), whereas the same was not true of species with low sperm intensity (overall meta-analytic mean: `r robust_model1.7_reparam$beta[2]`, 95% CI: `r robust_model1.7_reparam$ci.lb[2]` to `r robust_model1.7_reparam$ci.ub[2]`, p = `r p_value(robust_model1.7_reparam$pval[2])`) (Figure \@ref(fig:sperm)). Overall, there was no significant difference between species deemed to have high sperm intensity compared to those with low sperm intensity (Figure \@ref(fig:sperm)). 

```{r sperm, fig.width = 7.625, fig.height = 6.750, fig.cap="Species sperm competition intensity and the effect of changes in male harm on female fitness."}

sperm_data <- data %>% filter(!SCR.SCI == "hermaphrodite")

contrast_sperm <- paste0("$\\beta_{contrast}$ = ", round(robust_model1.7$beta[2], digit = 2))

contrast_sperm2 <- paste0("95% CI:", round(robust_model1.7$ci.lb[2], digit = 2), " to ", round(robust_model1.7$ci.ub[2], digit = 2))

contrast_sperm3 <- paste0("p = ", p_value(robust_model1.7$pval[2]))

sperm_plot = ggplot(sperm_data, aes(x = SCR.SCI, y = SMDH)) + 
              geom_violin(alpha = 0.1, aes(fill = SCR.SCI, colour = SCR.SCI)) + 
              geom_jitter(aes(x = SCR.SCI, y = SMDH, fill = SCR.SCI, colour = SCR.SCI, size = 1/sqrt(v_SMDH)),
                          width = 0.08, alpha = 0.1) + 
              ylim(c(-1.5, 6))+
              theme_bw() + 
		          theme(legend.background = element_blank(),
			                     legend.key = element_blank()) + 
              labs(x = "Sperm Competition Intensity", 
                   y = "SMDH", 
                   size = TeX("Precision $\\left(\\frac{1}{\\sqrt{v_{SMDH}}}\\right)$")) +
              #scale_x_discrete(labels = c("Both", "Direct", "Indirect")) +
              guides(size = guide_legend(override.aes = list(linetype = 0))) + 
              scale_colour_discrete(guide = FALSE) +
              scale_fill_discrete(guide = FALSE) + 
              annotate('text', x = (seq(1, 2, 1)), y = 6, 
                       label= paste0("italic(n)==", robust_model1.7_PI$n[1:2]), parse = TRUE, size = 3.5) +     
              annotate('text', x = (seq(1, 2, 1)), y = 5.7, 
                       label= paste0("italic(k)==", robust_model1.7_PI$nstdy[1:2]), parse = TRUE, size = 3.5) +     
        	  	# 95 %CI: branches
        	    geom_errorbar(data = robust_model1.7_PI,  aes(x = moderator, y = Est, ymin = lwr.CI, ymax = up.CI), 
                            show.legend = FALSE, size = 0.5, width = 0.05) +
              geom_point(data = robust_model1.7_PI, aes(x = moderator, y = Est, colour= moderator), size = 5) +
              geom_segment(aes(x = 1, y = 5.35, xend = 2, yend = 5.35), arrow = arrow(length = unit(0.1, "cm"), angle = 90, end = "both")) + 
  annotate('text', x = 1.5, y = 5, label = TeX(contrast_sperm), size = 3) + 
    annotate('text', x = 1.5, y = 4.6, label = TeX(contrast_sperm2), size = 3) + 
    annotate('text', x = 1.5, y = 4.2, label = TeX(contrast_sperm3), size = 3)

ggsave(plot = sperm_plot, filename = "fig4.png", path = "./output/figs", height = 7, width = 10, device = "png", dpi = 600)
sperm_plot

```


#### Species lifespan does not explain patterns in female harm
Female lifespan or the difference in lifespan between males and females of a species did not explain significant variation in female harm in treatments after controlling for sexual size dimorphism and harm type ($\beta_{lifespan_{f}}$ = `r robust_model1.9$b[2]`, 95% CI: `r robust_model1.9$ci.lb[2]` to `r robust_model1.9$ci.ub[2]`, t = `r robust_model1.9$zval[2]`, df = `r robust_model1.9$dfs`, p = `r robust_model1.9$pval[2]`; $\beta_{lifespan_{\Delta_{m-f}}}$ = `r robust_model1.11$b[2]`, 95% CI: `r robust_model1.11$ci.lb[2]` to `r robust_model1.11$ci.ub[2]`, t = `r robust_model1.11$zval[2]`, df = `r robust_model1.11$dfs`, p = `r robust_model1.11$pval[2]`)


#### Variation in female fitness

# References